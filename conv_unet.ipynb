{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avva14/image_generators/blob/main/conv_unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o8gfEJnIecg"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnXNwXwVIb6b"
      },
      "outputs": [],
      "source": [
        "!pip install pillow --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkO7fIPyIkiI"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/avva14/common_utils.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaGUrpc7IklE"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L51et3UZIkn0"
      },
      "outputs": [],
      "source": [
        "PATH_TO_TFDS = '/content/gdrive/MyDrive/tensorflow_datasets'\n",
        "PATH_TO_MODELS = '/content/gdrive/MyDrive/models/moire'\n",
        "PATH_TO_MOIRE = '/content/gdrive/MyDrive/Patterns/moiredata'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxwYYU5lIkqi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2 as cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bebCia9YIktq"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKsIgq10JYoZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "from math import ceil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1lK3Ay8JYrU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tre44uKPJYtz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zUAs3zVJeR5"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAYFEYwAJgkq"
      },
      "outputs": [],
      "source": [
        "ds = tfds.load('mnist', data_dir=PATH_TO_TFDS, download=False, split=['train', 'test'], shuffle_files=True)\n",
        "train_set = ds[0].cache().shuffle(1024).repeat().as_numpy_iterator()\n",
        "test_set = ds[1].cache().repeat().as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZ9orpXuJgnW"
      },
      "outputs": [],
      "source": [
        "rng = np.random.RandomState(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJM3ba3gJgp6"
      },
      "outputs": [],
      "source": [
        "SIZE = 208\n",
        "MNSZ = 28\n",
        "MAX_NOISE = 0.5\n",
        "MAX_NUM = 3\n",
        "num_classes = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39dFFloLJxfJ"
      },
      "outputs": [],
      "source": [
        "moirefiles = [os.path.join(PATH_TO_MOIRE, f) for f in os.listdir(PATH_TO_MOIRE)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joWY70l8JxiS"
      },
      "outputs": [],
      "source": [
        "from common_utils.unet_generators import UnetMaskTestGenerator, UnetMaskTrainGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NnI4HILJ2pv"
      },
      "source": [
        "## TF datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYOEQso5Jgs5"
      },
      "outputs": [],
      "source": [
        "def ugen_test():\n",
        "    return UnetMaskTestGenerator(test_set, rng, MAX_NUM, MAX_NOISE, MNSZ, SIZE)\n",
        "def ugen_train():\n",
        "    return UnetMaskTrainGenerator(train_set, rng, MAX_NUM, moirefiles, MAX_NOISE, MNSZ, SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_92SuovK26x"
      },
      "outputs": [],
      "source": [
        "dataset_test = tf.data.Dataset.from_generator(\n",
        "    ugen_test,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(SIZE,SIZE,1), dtype=np.float32),\n",
        "        tf.TensorSpec(shape=(SIZE,SIZE,1), dtype=np.float32)\n",
        "    )\n",
        ")\n",
        "dataset_train = tf.data.Dataset.from_generator(\n",
        "    ugen_train,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(SIZE,SIZE,1), dtype=np.float32),\n",
        "        tf.TensorSpec(shape=(SIZE,SIZE,1), dtype=np.float32)\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJJh6YZvK59K"
      },
      "outputs": [],
      "source": [
        "BATCHSIZE = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfA8z_dxK5_0"
      },
      "outputs": [],
      "source": [
        "batched_test = dataset_test.batch(BATCHSIZE)\n",
        "batched_train = dataset_train.batch(BATCHSIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lR6Ra_AK6Cc"
      },
      "outputs": [],
      "source": [
        "batched_test_iterator = batched_test.as_numpy_iterator()\n",
        "batched_train_iterator = batched_train.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "Bbva2l7ZZvRE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wCRNSCHLH4O"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model, load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixsVF2ghLlnc"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Layer, Conv2D, Conv2DTranspose, Lambda\n",
        "from keras.layers import Dropout, MaxPooling2D\n",
        "from keras.layers import ReLU, Concatenate, Cropping2D, UpSampling2D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2DPeriodic(Layer):\n",
        "    def __init__(self, filters, kernel_size):\n",
        "        super(Conv2DPeriodic, self).__init__()\n",
        "        margin = (kernel_size[0] - 1) // 2\n",
        "        self.la1 = Lambda(lambda x:x[:,-margin:,:,:])\n",
        "        self.la2 = Lambda(lambda x:x[:,:margin,:,:])\n",
        "        self.conv = Conv2D(filters=filters, kernel_size=kernel_size, padding='same')\n",
        "        self.merge = Concatenate(axis=1)\n",
        "        self.crop = Cropping2D((margin,0))\n",
        "\n",
        "    def call(self, x):\n",
        "        xt = self.la1(x)\n",
        "        xb = self.la2(x)\n",
        "        xe = self.merge([xt,x,xb])\n",
        "        x = self.conv(xe)\n",
        "        x = self.crop(x)\n",
        "        return x\n",
        "class ConvTransposePeriodic(Layer):\n",
        "    def __init__(self, filters, kernel_size, strides):\n",
        "        super(ConvTransposePeriodic, self).__init__()\n",
        "        margin = (kernel_size[0] - 1) // 2\n",
        "        self.la1 = Lambda(lambda x: x[:,-margin:,:,:])\n",
        "        self.la2 = Lambda(lambda x: x[:,:margin,:,:])\n",
        "        self.cont = Conv2DTranspose(filters=filters, kernel_size=kernel_size, strides=strides, padding='same')\n",
        "        self.mer = Concatenate(axis=1)\n",
        "        self.crp = Cropping2D((2*margin,0))\n",
        "\n",
        "    def call(self, x):\n",
        "        xt = self.la1(x)\n",
        "        xb = self.la2(x)\n",
        "        xm = self.mer([xt,x,xb])\n",
        "        x = self.cont(xm)\n",
        "        x = self.crp(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ZJQ8tgfLzuuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DROP = 0.1\n",
        "hidden_dim = 16"
      ],
      "metadata": {
        "id": "Y3EiPBC7nxi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-PewOBtLlp7"
      },
      "outputs": [],
      "source": [
        "class ContractingBlock(Layer):\n",
        "    def __init__(self, input_channels, drop=DROP):\n",
        "        super(ContractingBlock, self).__init__()\n",
        "        self.conv1 = Conv2DPeriodic(input_channels, (5,5))\n",
        "        self.conv2 = Conv2DPeriodic(input_channels, (5,5))\n",
        "        self.activation = ReLU()\n",
        "        self.maxpool = MaxPooling2D(pool_size=(2,2), strides=(2,2))\n",
        "        self.drop = Dropout(drop)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.drop(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureMapBlock(Layer):\n",
        "    def __init__(self, output_channels, name):\n",
        "        super(FeatureMapBlock, self).__init__(name=name)\n",
        "        self.conv = Conv2D(filters=output_channels, kernel_size=(1,1))\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Uf31RMRZn4yE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExpandingBlock(Layer):\n",
        "    def __init__(self, input_channels, drop=DROP):\n",
        "        super(ExpandingBlock, self).__init__()\n",
        "        self.upsample = ConvTransposePeriodic(input_channels, kernel_size=(5,5), strides=(2,2))\n",
        "        self.conv1 = Conv2DPeriodic(input_channels, kernel_size=(5,5))\n",
        "        self.conv2 = Conv2DPeriodic(input_channels, kernel_size=(5,5))\n",
        "        self.activation = ReLU()\n",
        "        self.drop = Dropout(drop)\n",
        "\n",
        "    def call(self, x, skip_con_x):\n",
        "        x = self.upsample(x)\n",
        "        x = Concatenate(axis=-1)([x, skip_con_x])\n",
        "        x = self.drop(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.activation(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "n3G-l0EBoCkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDEmCocvLH7p"
      },
      "outputs": [],
      "source": [
        "def unet(hidden_channels, num_stages, out_channels):\n",
        "    inputs = Input(shape=(SIZE,SIZE,1))\n",
        "    p = FeatureMapBlock(hidden_channels, 'input')(inputs)\n",
        "\n",
        "    xlist = []\n",
        "    nc = hidden_channels\n",
        "    for _ in range(num_stages):\n",
        "        xlist.append(p)\n",
        "        p = ContractingBlock(nc)(p)\n",
        "        nc *= 2\n",
        "\n",
        "    p = FeatureMapBlock(nc, 'bottleneck')(p)\n",
        "\n",
        "    for _ in range(num_stages):\n",
        "        nc /= 2\n",
        "        z = xlist.pop()\n",
        "        p = ExpandingBlock(nc)(p, z)\n",
        "\n",
        "    outputs = FeatureMapBlock(out_channels, 'output')(p)\n",
        "    model = Model(inputs=inputs, outputs=outputs, name='unet')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "So98_xP4LH-z"
      },
      "outputs": [],
      "source": [
        "unet_semantic = unet(hidden_dim, 4, num_classes+1)\n",
        "unet_semantic.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_8ePuoSVhqF"
      },
      "outputs": [],
      "source": [
        "aa, mm = next(batched_train_iterator)\n",
        "aa.shape, mm.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZaccK0PVb6N"
      },
      "outputs": [],
      "source": [
        "resaa = unet_semantic(aa, training=False)\n",
        "resaa.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3Z2p7ZSUytq"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6NEzZmhLvsq"
      },
      "outputs": [],
      "source": [
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "from keras.metrics import Metric, SparseCategoricalAccuracy\n",
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sprs_metr = SparseCategoricalAccuracy()\n",
        "sprs_loss = SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "1BwzpIjPqRjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NotZeroAccuracy(Metric):\n",
        "    def __init__(self, name=\"notzero_accuracy\", **kwargs):\n",
        "        super(NotZeroAccuracy, self).__init__(name=name, **kwargs)\n",
        "        self.not_zeros = self.add_weight(name='nz', initializer='zeros')\n",
        "\n",
        "    def update_state(self, y_true, y_pred):\n",
        "        truemaxposes = tf.cast(tf.squeeze(y_true), tf.int64)\n",
        "        predmaxposes = tf.argmax(y_pred, axis=-1)\n",
        "        true_nonzero = tf.greater(truemaxposes, 0)\n",
        "        where_equals = tf.logical_and(true_nonzero, tf.equal(predmaxposes, truemaxposes))\n",
        "\n",
        "        denom = tf.math.count_nonzero(true_nonzero)\n",
        "        numer = tf.math.count_nonzero(where_equals)\n",
        "        self.not_zeros.assign_add(tf.cast(tf.divide(numer, denom), tf.float32))\n",
        "    def result(self):\n",
        "        return self.not_zeros\n",
        "    def reset_state(self):\n",
        "        self.not_zeros.assign(0.)\n",
        ""
      ],
      "metadata": {
        "id": "GWgbdCa4q3df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sprs_nz_metr = NotZeroAccuracy()"
      ],
      "metadata": {
        "id": "9kv9OuYawST2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nonzeroaccuracy(y_true, y_pred):\n",
        "    truemaxposes = tf.cast(tf.squeeze(y_true), tf.int64)\n",
        "    predmaxposes = tf.argmax(y_pred, axis=-1)\n",
        "    true_nonzero = tf.greater(truemaxposes, 0)\n",
        "    where_equals = tf.logical_and(true_nonzero, tf.equal(predmaxposes, truemaxposes))\n",
        "\n",
        "    denom = tf.math.count_nonzero(true_nonzero)\n",
        "    numer = tf.math.count_nonzero(where_equals)\n",
        "    result = tf.divide(numer, denom)\n",
        "\n",
        "    return tf.reduce_mean(result)"
      ],
      "metadata": {
        "id": "ztm42vwXJImw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet_semantic.compile(optimizer=Adam(learning_rate=0.001), loss=sprs_loss, metrics=[sprs_metr, nonzeroaccuracy])"
      ],
      "metadata": {
        "id": "f8o4uOZXJmOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet_semantic.compile(optimizer=Adam(learning_rate=0.0001), loss=sprs_loss, metrics=[sprs_metr, nonzeroaccuracy])"
      ],
      "metadata": {
        "id": "YbSz97g_wdc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet_semantic.evaluate(batched_test, steps=10)"
      ],
      "metadata": {
        "id": "VwiX4yrqJng7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayc7uIXQMjwj"
      },
      "outputs": [],
      "source": [
        "history = unet_semantic.fit(\n",
        "    batched_train, steps_per_epoch=120, epochs=10, validation_data=batched_test, validation_steps=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dx5VcU9Lv2m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqs52FSVLv5c"
      },
      "outputs": [],
      "source": [
        "unet_semantic.save(os.path.join(PATH_TO_MODELS, \"conv_unet_v00\"), \"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ecw1kmFwdOOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DTQWuS0pT19R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from math import ceil"
      ],
      "metadata": {
        "id": "p7BYNFtqT4bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_colors = [\"#FFFFFF\", \"#FFAAAA\", \"#FFAA77\", \"#FFAA22\", \"#AAAA00\", \"#AA7700\", \"#FF4400\", \"#FF0000\", \"#AA0000\", \"#770000\", \"#220000\"]\n",
        "cmap = ListedColormap(set_colors, name=\"custom_cmap\")"
      ],
      "metadata": {
        "id": "U8UfObvKY1DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_batch(abatch, mbatch, nr, nc, NDIV=13):\n",
        "\n",
        "    PSIZ = SIZE // NDIV\n",
        "\n",
        "    fig, axxes = plt.subplots(ncols=nc,\n",
        "                              nrows=nr,\n",
        "                              figsize=(3*nc, 3*nr),\n",
        "                              sharey=True, sharex=True)\n",
        "\n",
        "    axxes = np.ravel(axxes)\n",
        "\n",
        "    for i, ax in enumerate(axxes):\n",
        "\n",
        "\n",
        "        if i % 2 == 0:\n",
        "            j = i // 2\n",
        "            a = abatch[j]\n",
        "            m = np.squeeze(mbatch[j]) if mbatch[j].shape[-1]==1 else np.argmax(mbatch[j], axis=-1)\n",
        "            ax.imshow(1-a, aspect=1, cmap='gray', vmin=0, vmax=1)\n",
        "        else:\n",
        "            ax.imshow(m, aspect=1, cmap=cmap, vmin=0, vmax=10, interpolation=None)\n",
        "\n",
        "        ax.set_yticks(PSIZ*np.arange(0, NDIV+1))\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_xticks(PSIZ*np.arange(0, NDIV+1))\n",
        "        ax.set_ylim(0,SIZE-1)\n",
        "        ax.set_xlim(0,SIZE-1)\n",
        "        ax.grid(color='g', linestyle='-.', linewidth=0.7, alpha=0.95)\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "a-8DG6CQfkCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resaa = unet_semantic(aa, training=False)\n",
        "resaa.shape"
      ],
      "metadata": {
        "id": "-wcOkSnST1_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_batch(aa, mm, 3, 4)"
      ],
      "metadata": {
        "id": "4pa6cFv8fmLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_batch(aa, resaa, 3, 4)"
      ],
      "metadata": {
        "id": "13ZXTLU3fmOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P8LrzvT0UfwE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvGOnona4L0mfvHjGWeFDf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}