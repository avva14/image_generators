{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avva14/image_generators/blob/main/conv_solidvit_semantic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o8gfEJnIecg"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnXNwXwVIb6b"
      },
      "outputs": [],
      "source": [
        "!pip install pillow --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkO7fIPyIkiI"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/avva14/common_utils.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaGUrpc7IklE"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L51et3UZIkn0"
      },
      "outputs": [],
      "source": [
        "PATH_TO_TFDS = '/content/gdrive/MyDrive/tensorflow_datasets'\n",
        "PATH_TO_MODELS = '/content/gdrive/MyDrive/models/moire'\n",
        "PATH_TO_MOIRE = '/content/gdrive/MyDrive/Patterns/moiredata'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxwYYU5lIkqi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2 as cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bebCia9YIktq"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKsIgq10JYoZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from math import ceil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1lK3Ay8JYrU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zUAs3zVJeR5"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAYFEYwAJgkq"
      },
      "outputs": [],
      "source": [
        "ds = tfds.load('mnist', data_dir=PATH_TO_TFDS, download=False, split=['train', 'test'], shuffle_files=True)\n",
        "train_set = ds[0].cache().shuffle(1024).repeat().as_numpy_iterator()\n",
        "test_set = ds[1].cache().repeat().as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZ9orpXuJgnW"
      },
      "outputs": [],
      "source": [
        "rng = np.random.RandomState(1)\n",
        "rng_safe = np.random.RandomState(21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJM3ba3gJgp6"
      },
      "outputs": [],
      "source": [
        "SIZE = 208\n",
        "MNSZ = 28\n",
        "NDIV = 13\n",
        "NDIV2 = NDIV*NDIV\n",
        "PSIZ = SIZE // NDIV\n",
        "MAX_NOISE = 0.5\n",
        "num_classes = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39dFFloLJxfJ"
      },
      "outputs": [],
      "source": [
        "moirefiles = [os.path.join(PATH_TO_MOIRE, f) for f in os.listdir(PATH_TO_MOIRE)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joWY70l8JxiS"
      },
      "outputs": [],
      "source": [
        "from common_utils.vit_generators import VitSolidTrainGenerator, VitSolidTestGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NnI4HILJ2pv"
      },
      "source": [
        "## TF datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYOEQso5Jgs5"
      },
      "outputs": [],
      "source": [
        "def vgen_test():\n",
        "    return VitSolidTestGenerator(test_set, rng, 2, num_classes, MAX_NOISE, MNSZ, SIZE, NDIV)\n",
        "def vgen_train():\n",
        "    return VitSolidTestGenerator(train_set, rng_safe, 2, num_classes, MAX_NOISE, MNSZ, SIZE, NDIV)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vgen_train():\n",
        "    return VitSolidTrainGenerator(train_set, rng, 2, num_classes, moirefiles, MAX_NOISE, MNSZ, SIZE, NDIV)"
      ],
      "metadata": {
        "id": "mwov8Kk8Lo4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_92SuovK26x"
      },
      "outputs": [],
      "source": [
        "dataset_test = tf.data.Dataset.from_generator(\n",
        "    vgen_test,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(SIZE,SIZE,1), dtype=np.float32),\n",
        "        tf.TensorSpec(shape=(NDIV2), dtype=np.float32)\n",
        "    )\n",
        ")\n",
        "dataset_train = tf.data.Dataset.from_generator(\n",
        "    vgen_train,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(SIZE,SIZE,1), dtype=np.float32),\n",
        "        tf.TensorSpec(shape=(NDIV2), dtype=np.float32)\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJJh6YZvK59K"
      },
      "outputs": [],
      "source": [
        "BATCHSIZE = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfA8z_dxK5_0"
      },
      "outputs": [],
      "source": [
        "batched_test = dataset_test.batch(BATCHSIZE)\n",
        "batched_train = dataset_train.batch(BATCHSIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lR6Ra_AK6Cc"
      },
      "outputs": [],
      "source": [
        "batched_test_iterator = batched_test.as_numpy_iterator()\n",
        "batched_train_iterator = batched_train.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aa, mm = batched_train_iterator.next()\n",
        "aa.shape, mm.shape"
      ],
      "metadata": {
        "id": "WsWs6chi2UrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aa, mm = batched_test_iterator.next()\n",
        "aa.shape, mm.shape"
      ],
      "metadata": {
        "id": "tILfghkTSh86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize data"
      ],
      "metadata": {
        "id": "l5KlLjH95kP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_batch(abatch, mbatch, nr, nc):\n",
        "\n",
        "    fig, axxes = plt.subplots(ncols=2*nc,\n",
        "                              nrows=nr,\n",
        "                              figsize=(6*nc, 3*nr),\n",
        "                              sharey=False, sharex=False)\n",
        "\n",
        "    axxes = np.ravel(axxes)\n",
        "\n",
        "    for i, ax in enumerate(axxes):\n",
        "\n",
        "        if i % 2 == 0:\n",
        "            j = i // 2\n",
        "            a = abatch[j]\n",
        "            m = mbatch[j].astype(np.int32) if len(mbatch[j].shape)==1 else np.argmax(mbatch[j], axis=-1)\n",
        "\n",
        "            ax.imshow(1-a, aspect=1, cmap='gray', vmin=0, vmax=1)\n",
        "\n",
        "            ixes = np.where(m > 0)[0]\n",
        "            ax.scatter(PSIZ*(ixes % NDIV) + PSIZ//2, PSIZ*(ixes // NDIV) + PSIZ//2, s=2)\n",
        "\n",
        "            ax.set_yticks(PSIZ*np.arange(0, NDIV+1))\n",
        "            ax.set_xticks(PSIZ*np.arange(0, NDIV+1))\n",
        "            ax.set_ylim(0,SIZE-1)\n",
        "            ax.set_xlim(0,SIZE-1)\n",
        "            ax.grid(color='g', linestyle='-.', linewidth=0.7, alpha=0.95)\n",
        "        else:\n",
        "            for p in ixes:\n",
        "                ax.text((p%NDIV)+0.3,(p//NDIV)+0.3,f'{m[p]-1}')\n",
        "\n",
        "            ax.set_yticks(np.arange(0, NDIV+1))\n",
        "            ax.set_xticks(np.arange(0, NDIV+1))\n",
        "            ax.set_ylim(0,NDIV)\n",
        "            ax.set_xlim(0,NDIV)\n",
        "            ax.grid(color='g', linestyle='-.', linewidth=0.7, alpha=0.95)\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "71JDXpTr5nDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def displayres_batch(abatch, mbatch, resbatch, nr, nc):\n",
        "\n",
        "    fig, axxes = plt.subplots(ncols=3*nc,\n",
        "                              nrows=nr,\n",
        "                              figsize=(9*nc, 3*nr),\n",
        "                              sharey=False, sharex=False)\n",
        "\n",
        "    axxes = np.ravel(axxes)\n",
        "\n",
        "    for i, ax in enumerate(axxes):\n",
        "\n",
        "        if i % 3 == 0:\n",
        "            j = i // 3\n",
        "            a = abatch[j]\n",
        "            m = mbatch[j].astype(np.int32)\n",
        "            r = np.argmax(resbatch[j], axis=-1)\n",
        "\n",
        "            ax.imshow(1-a, aspect=1, cmap='gray', vmin=0, vmax=1)\n",
        "\n",
        "            ixes = np.where(m > 0)[0]\n",
        "            jxes = np.where(r > 0)[0]\n",
        "            ax.scatter(PSIZ*(ixes % NDIV) + PSIZ//2, PSIZ*(ixes // NDIV) + PSIZ//2, s=2)\n",
        "\n",
        "            ax.set_yticks(PSIZ*np.arange(0, NDIV+1))\n",
        "            ax.set_xticks(PSIZ*np.arange(0, NDIV+1))\n",
        "            ax.set_ylim(0,SIZE-1)\n",
        "            ax.set_xlim(0,SIZE-1)\n",
        "            ax.grid(color='g', linestyle='-.', linewidth=0.7, alpha=0.95)\n",
        "        elif i % 3 == 1:\n",
        "            for p in ixes:\n",
        "                ax.text((p%NDIV)+0.3,(p//NDIV)+0.3,f'{m[p]-1}')\n",
        "\n",
        "            ax.set_yticks(np.arange(0, NDIV+1))\n",
        "            ax.set_xticks(np.arange(0, NDIV+1))\n",
        "            ax.set_ylim(0,NDIV)\n",
        "            ax.set_xlim(0,NDIV)\n",
        "            ax.grid(color='g', linestyle='-.', linewidth=0.7, alpha=0.95)\n",
        "        else:\n",
        "            for p in jxes:\n",
        "                col = 'black' if r[p]==m[p] else 'red'\n",
        "                ax.text((p%NDIV)+0.3,(p//NDIV)+0.3,f'{r[p]-1}',c=col)\n",
        "\n",
        "            ax.set_yticks(np.arange(0, NDIV+1))\n",
        "            ax.set_xticks(np.arange(0, NDIV+1))\n",
        "            ax.set_ylim(0,NDIV)\n",
        "            ax.set_xlim(0,NDIV)\n",
        "            ax.grid(color='g', linestyle='-.', linewidth=0.7, alpha=0.95)\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "TAsnHOEoEUhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_batch(aa, mm, 3, 2)"
      ],
      "metadata": {
        "id": "29W5DfLg5rXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention mask"
      ],
      "metadata": {
        "id": "6D1gI1Ds7SRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from common_utils.picutils import intersection, intersectionp"
      ],
      "metadata": {
        "id": "nRTpHJAf7U8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nnneighbors(p1, p2):\n",
        "    x1 = p1 % NDIV\n",
        "    y1 = p1 // NDIV\n",
        "    x2 = p2 % NDIV\n",
        "    y2 = p2 // NDIV\n",
        "    closex = intersection(x1-1, x1+1, x2, x2)\n",
        "    closey = intersectionp(y1-1, y1+1, y2, y2, NDIV)\n",
        "    return closex and closey"
      ],
      "metadata": {
        "id": "dBYoEbpR7U_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "atten_mask = np.reshape([nnneighbors(pp//NDIV2, pp%NDIV2) for pp in range(NDIV2*NDIV2)], (NDIV2,NDIV2)).astype(bool)"
      ],
      "metadata": {
        "id": "-5JcmPHa7VBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gLSgjea37gvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EGi4W0BI7gy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PSIZ"
      ],
      "metadata": {
        "id": "DJzwJD5R7g2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize mask"
      ],
      "metadata": {
        "id": "5T0e5qmB5Ys9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ixtoshow = np.where(mm[0]>0)[0]\n",
        "nc = 2\n",
        "nr = ceil(len(ixtoshow)/nc)\n",
        "\n",
        "fig, axxes = plt.subplots(ncols=nc,\n",
        "                          nrows=nr,\n",
        "                          figsize=(2*nc, 2*nr),\n",
        "                          sharey=True, sharex=True)\n",
        "\n",
        "axxes = np.ravel(axxes)\n",
        "\n",
        "for i, x in enumerate(axxes):\n",
        "    if i >= len(ixtoshow):\n",
        "        x.axis('off')\n",
        "        continue\n",
        "    p = ixtoshow[i]\n",
        "    x.imshow(1-aa[0], aspect=1, cmap='gray')\n",
        "    x.scatter((np.where(atten_mask[p])[0] % NDIV)*PSIZ+PSIZ//2,\n",
        "              (np.where(atten_mask[p])[0] // NDIV)*PSIZ+PSIZ//2)\n",
        "    x.set_ylim(0,SIZE)\n",
        "    x.set_xlim(0,SIZE)\n",
        "    x.set_yticks(PSIZ*np.arange(0, NDIV+1))\n",
        "    x.set_xticks(PSIZ*np.arange(0, NDIV+1))\n",
        "    x.grid(color='g', linestyle='-.', linewidth=0.7, alpha=0.95)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RSUZWg6G5XpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "Bbva2l7ZZvRE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wCRNSCHLH4O"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, Lambda, Cropping2D, Concatenate, ReLU, MaxPooling2D"
      ],
      "metadata": {
        "id": "5ysf46cQ40xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixsVF2ghLlnc"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Layer, Embedding\n",
        "from keras.layers import LayerNormalization, MultiHeadAttention, Add, Flatten, Dropout, Dense\n",
        "from keras.layers import Reshape, Permute"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "projection_dim = 64\n",
        "num_heads = 4\n",
        "transformer_units = [projection_dim * 2, projection_dim]\n",
        "eps = 1e-6\n",
        "DROP = 0.1"
      ],
      "metadata": {
        "id": "FeNg2akjv55v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2DPeriodic(Layer):\n",
        "    def __init__(self, filters, kernel_size):\n",
        "        super(Conv2DPeriodic, self).__init__()\n",
        "        margin = (kernel_size[0] - 1) // 2\n",
        "        self.la1 = Lambda(lambda x:x[:,-margin:,:,:])\n",
        "        self.la2 = Lambda(lambda x:x[:,:margin,:,:])\n",
        "        self.conv = Conv2D(filters=filters, kernel_size=kernel_size, padding='same')\n",
        "        self.merge = Concatenate(axis=1)\n",
        "        self.crop = Cropping2D((margin,0))\n",
        "\n",
        "    def call(self, x):\n",
        "        xt = self.la1(x)\n",
        "        xb = self.la2(x)\n",
        "        xe = self.merge([xt,x,xb])\n",
        "        x = self.conv(xe)\n",
        "        x = self.crop(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "aSagWp_rv6AM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ContractingBlock(Layer):\n",
        "    def __init__(self, num_channles):\n",
        "        super(ContractingBlock, self).__init__()\n",
        "        self.con1 = Conv2DPeriodic(num_channles, kernel_size=(5,5))\n",
        "        self.con2 = Conv2DPeriodic(num_channles, kernel_size=(5,5))\n",
        "        self.relu = ReLU()\n",
        "        self.pool = MaxPooling2D((2,2))\n",
        "        self.drop = Dropout(0.1)\n",
        "    def call(self, x):\n",
        "        x = self.con1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.con2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.drop(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "3IE0ABIVCxsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvPatcherEmbedder(Model):\n",
        "    def __init__(self, imgsize, projectiondim, patchnum):\n",
        "        super(ConvPatcherEmbedder, self).__init__()\n",
        "\n",
        "        self.dim = projectiondim\n",
        "        self.patchnum2 = patchnum*patchnum\n",
        "        self.patchsize = imgsize // patchnum\n",
        "\n",
        "        self.conv1 = ContractingBlock(projectiondim//2)\n",
        "        self.conv2 = ContractingBlock(projectiondim//2)\n",
        "        self.conv3 = ContractingBlock(projectiondim)\n",
        "        self.conv4 = ContractingBlock(projectiondim)\n",
        "        self.reshape = Reshape((-1,projectiondim))\n",
        "        self.positions = tf.range(start=0, limit=self.patchnum2, delta=1)\n",
        "\n",
        "        self.position_embedding = Embedding(input_dim=self.patchnum2, output_dim=projectiondim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        coded = self.conv1(inputs)\n",
        "        coded = self.conv2(coded)\n",
        "        coded = self.conv3(coded)\n",
        "        coded = self.conv4(coded)\n",
        "        coded = self.reshape(coded)\n",
        "        pos_embed = self.position_embedding(self.positions)\n",
        "\n",
        "        emd = coded + pos_embed\n",
        "        return emd\n",
        "    def get_config(self):\n",
        "        return {\"project_dim\": self.dim, \"patch_size\": self.patchsize}"
      ],
      "metadata": {
        "id": "5f5DOIRRCxxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o98fT_ZBCx0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pe = ConvPatcherEmbedder(SIZE, projection_dim, NDIV)"
      ],
      "metadata": {
        "id": "iXa_9Ct7v6Dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "respe = pe(aa, training=False)\n",
        "respe.shape"
      ],
      "metadata": {
        "id": "k2VoACUv2SbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pe.summary()"
      ],
      "metadata": {
        "id": "NAbLUXCI3Oa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SkippedMultiHeadAttention(Layer):\n",
        "    def __init__(self, numheads, projectiondim, droprate, mask=None):\n",
        "        super(SkippedMultiHeadAttention, self).__init__()\n",
        "        self.ln = LayerNormalization(epsilon=eps)\n",
        "        self.add = Add()\n",
        "        self.mha = MultiHeadAttention(num_heads=numheads, key_dim=projectiondim, dropout=droprate)\n",
        "        self.mask = None\n",
        "        if mask is not None:\n",
        "            self.mask = tf.cast(tf.convert_to_tensor(mask), tf.bool)\n",
        "\n",
        "    def call(self, x):\n",
        "        x1 = self.ln(x)\n",
        "        ao, scores = self.mha(x1, x1, attention_mask=self.mask, return_attention_scores=True)\n",
        "        x2 = self.add([ao, x1])\n",
        "        return x2, scores\n",
        "\n",
        "class SkippedMultiLayer(Layer):\n",
        "    def __init__(self, transformerunits, dropoutrate):\n",
        "        super(SkippedMultiLayer, self).__init__()\n",
        "        self.ln = LayerNormalization(epsilon=eps)\n",
        "        self.add = Add()\n",
        "        self.drop = Dropout(dropoutrate)\n",
        "        self.denses = []\n",
        "        for units in transformerunits:\n",
        "            self.denses.append(Dense(units, activation=tf.nn.gelu))\n",
        "\n",
        "    def call(self, x2):\n",
        "        x3 = self.ln(x2)\n",
        "        for l in self.denses:\n",
        "            x3 = l(x3)\n",
        "            x3 = self.drop(x3)\n",
        "        x = self.add([x3, x2])\n",
        "        return x\n",
        "\n",
        "class OutputMultiLayer(Layer):\n",
        "    def __init__(self, transformerunits, dropoutrate):\n",
        "        super(OutputMultiLayer, self).__init__()\n",
        "        self.ln = LayerNormalization(epsilon=eps)\n",
        "        self.flat = Flatten()\n",
        "        self.drop = Dropout(dropoutrate)\n",
        "        self.denses = []\n",
        "        for units in transformerunits:\n",
        "            self.denses.append(Dense(units, activation=tf.nn.gelu))\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.ln(x)\n",
        "        x = self.flat(x)\n",
        "        for l in self.denses:\n",
        "            x = l(x)\n",
        "            x = self.drop(x)\n",
        "        return x\n",
        "\n",
        "class SelfAttention(Model):\n",
        "    def __init__(self, numheads, projectiondim, attenmask, transformerunits, drop):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.dim = projectiondim\n",
        "        self.heads = numheads\n",
        "        self.units = transformerunits\n",
        "        self.drop = drop\n",
        "        self.mha = []\n",
        "        self.ml = []\n",
        "        for units in transformerunits:\n",
        "            self.mha.append(SkippedMultiHeadAttention(numheads, projectiondim, drop, attenmask))\n",
        "            self.ml.append(SkippedMultiLayer(transformerunits, drop))\n",
        "\n",
        "    def call(self, x):\n",
        "        for a, b in zip(self.mha, self.ml):\n",
        "            x, s = a(x)\n",
        "            x = b(x)\n",
        "        return x, s\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\n",
        "            \"project_dim\": self.dim,\n",
        "            \"num_heads\": self.heads,\n",
        "            \"transformer_units\": self.units,\n",
        "            \"drop\": self.drop,\n",
        "            }"
      ],
      "metadata": {
        "id": "ZJQ8tgfLzuuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sa = SelfAttention(num_heads, projection_dim, atten_mask, transformer_units, DROP)"
      ],
      "metadata": {
        "id": "z0jC1K9C3naU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ressa, resscore = sa(respe, training=False)\n",
        "ressa.shape, resscore.shape"
      ],
      "metadata": {
        "id": "H8RDJNOz3nc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sa.summary()"
      ],
      "metadata": {
        "id": "jxjIXPIj3nfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ToSemanticFeature(Model):\n",
        "    def __init__(self, hidden, numclass):\n",
        "        super(ToSemanticFeature, self).__init__()\n",
        "        self.dens1 = Dense(hidden, activation='relu')\n",
        "        self.dens2 = Dense(numclass)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.dens1(x)\n",
        "        x = self.dens2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "lh9qBRBk3nic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sf = ToSemanticFeature(2*projection_dim, num_classes+1)"
      ],
      "metadata": {
        "id": "IEsMinVY4a-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ressf = sf(ressa, training=False)\n",
        "ressf.shape"
      ],
      "metadata": {
        "id": "FzP_2jmQ4bAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sf.summary()"
      ],
      "metadata": {
        "id": "xmFMJ-7h4pPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model"
      ],
      "metadata": {
        "id": "jKKqF6_44vGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input"
      ],
      "metadata": {
        "id": "bdkyMBSX461W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pe = load_model(os.path.join(PATH_TO_MODELS, \"pe_semantic_v05\"))\n",
        "# sa = load_model(os.path.join(PATH_TO_MODELS, \"sa_semantic_v05\"))\n",
        "# sf = load_model(os.path.join(PATH_TO_MODELS, \"sf_semantic_v05\"))"
      ],
      "metadata": {
        "id": "UXE-SzEQ4t2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assemble model"
      ],
      "metadata": {
        "id": "YuJy0lNE40t-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vit_semantic(encod, selfattention, finall):\n",
        "    inputs = Input(shape=(SIZE, SIZE, 1))\n",
        "\n",
        "    encoded_patches = encod(inputs)\n",
        "    features, scores = selfattention(encoded_patches)\n",
        "\n",
        "    logts = finall(features)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=[logts, scores], name='vit_detect')\n",
        "    return model"
      ],
      "metadata": {
        "id": "a9OICE6m4pR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_model = create_vit_semantic(pe, sa, sf)\n",
        "vit_model.summary()"
      ],
      "metadata": {
        "id": "4wkjyiVc46wE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZaccK0PVb6N"
      },
      "outputs": [],
      "source": [
        "resaa, resscore = vit_model(aa, training=False)\n",
        "resaa.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3Z2p7ZSUytq"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6NEzZmhLvsq"
      },
      "outputs": [],
      "source": [
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "from keras.metrics import SparseCategoricalAccuracy\n",
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_metr = SparseCategoricalAccuracy()\n",
        "cat_loss = SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "1BwzpIjPqRjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_loss(mm, resaa)"
      ],
      "metadata": {
        "id": "zNqF7ijfYH9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nonzeroaccuracy(y_true, y_pred):\n",
        "    truemaxposes = tf.cast(tf.squeeze(y_true), tf.int64)\n",
        "    predmaxposes = tf.argmax(y_pred, axis=-1)\n",
        "    true_nonzero = tf.greater(truemaxposes, 0)\n",
        "    where_equals = tf.logical_and(true_nonzero, tf.equal(predmaxposes, truemaxposes))\n",
        "\n",
        "    denom = tf.math.count_nonzero(true_nonzero)\n",
        "    numer = tf.math.count_nonzero(where_equals)\n",
        "    result = tf.divide(numer, denom)\n",
        "\n",
        "    return tf.reduce_mean(result)"
      ],
      "metadata": {
        "id": "BX9vPLVV50yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelTrain(Model):\n",
        "    def __init__(self, mdl, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.model = mdl\n",
        "\n",
        "    def compile(self, optimizer, losspos, metricpos, **kwargs):\n",
        "        super().compile(**kwargs)\n",
        "        self.opt = optimizer\n",
        "        self.loss_posit = losspos\n",
        "        self.metr_posit = metricpos\n",
        "\n",
        "    def train_step(self, batch, **kwargs):\n",
        "        X, y = batch\n",
        "        with tf.GradientTape() as tape:\n",
        "            bx, sc = self.model(X)\n",
        "            loss = self.loss_posit(y, bx)\n",
        "            grad = tape.gradient(loss, self.model.trainable_variables)\n",
        "        self.opt.apply_gradients(zip(grad, self.model.trainable_variables))\n",
        "        acc = self.metr_posit(y, bx)\n",
        "        return {\"loss\":loss, \"acc\":acc}\n",
        "\n",
        "    def test_step(self, batch, **kwargs):\n",
        "        X, y = batch\n",
        "        bx, sc = self.model(X, training=False)\n",
        "        loss = self.loss_posit(y, bx)\n",
        "        acc = self.metr_posit(y, bx)\n",
        "        return {\"loss\":loss, \"acc\":acc}\n",
        "\n",
        "    def call(self, X, **kwargs):\n",
        "        return self.model(X, **kwargs)"
      ],
      "metadata": {
        "id": "f8o4uOZXJmOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VF4NDENoY63m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_train = ModelTrain(vit_model)"
      ],
      "metadata": {
        "id": "YbSz97g_wdc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d8fH2tLDY8Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_train.compile(Adam(learning_rate=0.0001), cat_loss, nonzeroaccuracy)"
      ],
      "metadata": {
        "id": "VwiX4yrqJng7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayc7uIXQMjwj"
      },
      "outputs": [],
      "source": [
        "vit_train.evaluate(batched_test, steps=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dx5VcU9Lv2m"
      },
      "outputs": [],
      "source": [
        "history = vit_train.fit(batched_train, steps_per_epoch=100, epochs=20, validation_data=batched_test, validation_steps=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RcO2JfHT6iwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EXA_BW9E6izK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqs52FSVLv5c"
      },
      "outputs": [],
      "source": [
        "pe.save(os.path.join(PATH_TO_MODELS, \"pe_conv_semantic_v05\"), \"tf\")\n",
        "sa.save(os.path.join(PATH_TO_MODELS, \"sa_conv_semantic_v05\"), \"tf\")\n",
        "sf.save(os.path.join(PATH_TO_MODELS, \"sf_conv_semantic_v05\"), \"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resaa, resscore = vit_model(aa, training=False)\n",
        "resaa.shape"
      ],
      "metadata": {
        "id": "ecw1kmFwdOOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p7BYNFtqT4bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yB1-APgr-fKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ov4zJ6MlnPOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4pa6cFv8fmLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "displayres_batch(aa, mm, resaa, 3, 2)"
      ],
      "metadata": {
        "id": "13ZXTLU3fmOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P8LrzvT0UfwE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMroCpBPyET2tVzAwyvPjnO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}